
\begin{block}{Markov Decision Process (MDP)}
\vspace{0.15cm}
    \begin{center}
    \includegraphics[width=0.95\linewidth]{fig/mdp.png}    
  \end{center}
  \vspace{0.15cm}
\end{block}

\begin{block}{\normalsize{Multi-model Markov Decision Processes (MMDPs)}}
    \begin{center}
    \includegraphics[width=0.83\linewidth]{fig/mmdps.png}
  \end{center}
 
  \begin{itemize}
     \item Mean return across the uncertain true models
     \[
       \rho(\pi)= \mathbb{E}^{\lambda} \left[  \mathbb{E}^{\pi,p^{\tilde{m}},\mu} \left[ \sum_{t=1}^{T}  r_{t}^{\tilde{m}}(\tilde{s}_{t},\tilde{a}_{t}) \mid \tilde{m} \right] \right]  \quad\quad(1).  
     \]
     \item Optimal policy $\rho^* $
     \[
      \rho^* = \max_{\pi \in \Pi}\rho(\pi).
     \]
    
\end{itemize}
\end{block}






%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
