\begin{block}{\normalsize{Inverse Reinforcement Learning (IRL)}}
     \[
       \rho(\pi, r) = \lim_{T \to \infty} \mathbb{E}^{\pi, p_0} \lbrack \sum_{t=0}^{T} \gamma^t r(\tilde{s}_t, \pi(\tilde{s}_t)) \rbrack
     \]
     \[ 
       \pi^*_{IRL} = \argmin_{\pi \in \Pi} \max_{r \in \mathcal{R}} \rho(\hat{\pi}_e, r) - \rho(\pi, r)
     \]
     \[
       \pi^*_{ROIL} = \argmin_{\pi \in \Pi} \max_{\pi_e \in \Pi} \max_{r \in \mathcal{R}} \rho(\pi_e, r) - \rho(\pi, r)
     \]
\end{block}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
